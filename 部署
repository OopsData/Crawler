1、爬虫项目名称:Crawler
2、爬虫项目repo:git@github.com:gaoguoxin/Crawler.git
3、爬虫gem项目名称:movie_spider
4、爬虫gem项目repo:git@github.com:gaoguoxin/movie_spider.git
5、从上述两个仓库中clone代码到本地同一工作目录下,并分别bundle(先在movie_spider目录bundle,之后在Crawler目录bundle),做好数据库配置
6、在Crawler项目中找到Task这个model,所有的爬虫任务都用Task这个model来完成
    对于新闻数据和电影数据,需要事先添加任务到Task这个model,具体添加方法,我在Crawler目录有文件说明.
       Task有两个非常重要的字段:
         status:0表示这个任务的数据不再爬取,1表示这个任务会爬取(如果要禁用或者启用哪个任务的话手动修改这个值即可)
         type:任务类型,目前有两种任务类型,news和video分别表示新闻任务和视频任务
    对于其他任务(cctv6新闻任务,贴吧任务)则不需要添加task,直接在执行函数中修改数据源(url)并执行即可
7、关于执行
	Task.runing_movie_tasks  # 爬取视频任务,完成后会将数据存入movie这个表并将结果导出为.xls文件并放到 /public/export/xxxx-xxx-xx_video.xls,日期为当前日期的前一天

	Task.runing_news_tasks   # 爬取新闻任务,完成后会将数据存入Administrivium这个model并将结果导出为.xls文件并放到 /public/export/xxxx-xxx-xx_news.xls,日期为当前日期的前一天

	Task.runing_stars_news   # CCTV6 新闻任务,关键词直接在函数中修改,直接在console执行即可,结果不会存入数据库,而是直接导出到/public/export/xxx.xls  xxx 表示关键字

	Task.runing_tieba_tasks  # 贴吧任务,贴吧的url和爬取的最大页数需要人工确定,如果不确定最大爬取页数的话会把该明星的所有数据都爬下来,会浪费很长时间,确定后直接执行即可,数据会存到TiebaInfo这个model,并将结果导出到'/public/export/贴吧_xxx-xx-xx_{star}.xls   xxx-xx-xx表示前一天,star表示明星的名字



